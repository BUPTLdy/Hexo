---
layout:     post
title:      "Ways for Visualizing Convolutional Networks"
subtitle:   ""
date:       2016-09-25 10:00:00
author:     "Ldy"
header-img: "img/tag-bg1.jpg"
tags:
    - CNN
    - Deep Learning
---

![](http://7xritj.com1.z0.glb.clouddn.com/%E9%80%89%E5%8C%BA_005.jpg)
<!--more-->
近年来，卷积神经网络（CNN）在海量数据的物体分类、识别取得了巨大的成功，但是我们对CNN为什么能够取得这么好的效果以及其中间层所计算得到的特征的理解却是远远落后与CNN的应用。更多的时候CNN对于我们来说就像个黑盒子，输入数据和便签进行训练，然后就可以拟合出我们想要的结果。
![](http://7xritj.com1.z0.glb.clouddn.com/16-9-18/80287570.jpg)

如果不能弄明白CNN为什么能够工作的这么好，构建一个好的CNN模型就只能靠试错。为了对CNN有个直观的了解，近年来有许多工作围绕着CNN可视化来展开。
![](http://7xritj.com1.z0.glb.clouddn.com/16-9-18/38360122.jpg)

目前CNN的可视化方法主要分为两种：

(1) 前向计算可视化

通过前向计算直接可视化深度卷积网络每层的feature map，然后观察feature map的数值变化。一个训练成功的CNN网络，其feature map的值伴随网络深度的增加，会越来越稀疏。

(2)反向计算可视化

反向信号向后传播将低维的feature maps 还原到原图像空间，可视化该feature map被原图哪部分特征激活，从而理解该feature map从原图像学习了何种特征。

本文后面的内容也主要围绕这两方面展开。

## 模型介绍

在介绍一些具体的可视化方法之前，我们先介绍一下我们使用的模型,我们使用的网络是经过CaffeNet微调，用来分类21类光学遥感图像的模型，具体内容可参考[CNN在光学遥感图像上的应用](http://buptldy.github.io/2016/06/12/2016-06-12-CNN%E5%9C%A8%E5%85%89%E5%AD%A6%E9%81%A5%E6%84%9F%E5%9B%BE%E5%83%8F%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/)。

CaffeNet其实就是AlexNet在Caffe上的实现，为了适应我们具体的分类任务，输出层改为21个节点。
![](http://7xritj.com1.z0.glb.clouddn.com/16-5-23/18035393.jpg)

其中要分类的21类光学遥感图像如下图所示：

![](http://7xritj.com1.z0.glb.clouddn.com/16-5-22/46888988.jpg)

## 前向计算可视化

### 特征可视化

通过可视化CNN计算得到的特征通常是大家都能想到的事情，通常第一层能提取到的特征能够和图像对应上，但是到了CNN的更高层，提取到的特征就变的更加抽象，不容易解释。

如下图所示，Input为输入图像，Filter为CNN第一层卷积层所学
习到的参数，可视化后其实就是一个个抽取边缘的滤波器，然后Output为CNN第一层卷积层所提取到的特征，从图中可以看出来输入图像经过CNN第一层卷积层之后得到了边缘特征。
![](http://7xritj.com1.z0.glb.clouddn.com/16-9-18/70836148.jpg)

但是CNN高层滤波器对前面输入特征的组合，提取得到的高维特征就不怎么好解释了，如下图所示，顺着箭头方向依次为上述输入图片通过CNN高层卷积层所提取到的特征，可以发现特征随着网络的加深，会越来越抽象、越来越稀疏。

![](http://7xritj.com1.z0.glb.clouddn.com/16-9-18/23256006.jpg)


### t-SNE visualization

有时为了体现CNN提取到特征的相关性，我们可以把提取到的特征经行t-SNE降维，然后在二维平面显示出来，如下图所示。从下图可以看出，视觉上看上去相似的图片，在降维后在平面上也很靠近。我们提取的是fc7层的特征（也称为CNN-Code）,t-SNE降维为2维向量显示如下。
![](http://7xritj.com1.z0.glb.clouddn.com/16-9-18/89427613.jpg)

### 遮挡实验

如下图，左边的图为输入图像，注意上边的黑色遮挡区域，我们在输入图像上逐渐移动遮挡区域，然后记录对应输入图像所对应的正确类别的输出概率。很容易理解，当我们遮挡住输入图像的关键区域时，对应的正确输出概率会很低，从下图也可以看出来，当遮挡住飞机的关键部位时，CNN判别为飞机场的概率下降到0.2以下。说明CNN模型确实学习到了物体的关键部分，而不是只依靠一些上下文环境，遮挡实验的代码可参考：[occlusion_experiments](https://github.com/BUPTLdy/occlusion_experiments)。

![](http://7xritj.com1.z0.glb.clouddn.com/16-9-19/45188603.jpg)


## 反向计算可视化

前面介绍的几种前向计算可视化的方法都比较好理解，但是还是不能解释CNN深层提取到的特征究竟是什么，究竟对应了输入图像的哪一部分。



### 反向求导可视化

在探讨对图像反向求导可视化之前，我们先看看那一个线性分类器，公式如下：

$$f(x\_i)=Wx\_i+b$$

$W$为线性分类器权值、$x\_i$表示一幅输入图像，$b$为偏置。如下图所示，$W$为线性分类器的权值维度为`[3×4]`，3表示要分类的数目，4表示为图片的每一个像素值打分;其中$x_i$为一幅图像展成的列向量，维度为`[4×1]`;$b$的维度为`[3×1]`,所以$Wx\_i+b$得到一个`[3×1]`的向量表示当前输入图像$x\_i$在每个类别上的打分，其中最高分预判为输入图像的类别。通过上述分析
可知$W$值决定了图像中的对应像素的重要性，某一类中某个像素越重要，则其对应的权值越大。
![](http://7xritj.com1.z0.glb.clouddn.com/16-9-21/40364595.jpg)

对于CNN来说因为有很多层非线性函数，$f(x\_i)$为一个高度非线性话的分类器，不过我们可以把它看做一个整体，近似的等于一个线性分类器：

$$f(x_i) \approx Wx\_i+b$$

然后我们可以对某个输入图片$x_0$上对上式求导，得打权值$W$，也就得到了对应输入图片的重要性大小。

$$W = \frac{\partial f(x\_i)}{\partial I}\vert \_{x\_0}$$

产生的图像如下图所示，不是很明显，仔细看能看出飞机的轮廓。
![](http://7xritj.com1.z0.glb.clouddn.com/16-9-22/81010256.jpg)

### 欺骗CNN网络

上面讨论了通过对图片求导来得到对应图片像素的重要性，我们可以利用上面求到的图像导数来欺骗CNN网络，如下图所示坐上图为输入图片类别为`airplane`，然后给定一个目标类别`denseresidential`,我们通过对输入图像求梯度上升来最大化目标类别的输出，求得的梯度累加到输入图像上，知道CNN判别为目标类别。下图中我们可以看出，上面的两个图人眼看起来都是`airplane`类别，差别看起来也不大，但是CNN判别第二张图为`denseresidential`类比，从某种意义上说我们欺骗了CNN。

![](http://7xritj.com1.z0.glb.clouddn.com/16-9-22/31659955.jpg)

### Class Model Visualisation

对于一个训练好的CNN模型，我们可以通过随机产生一张带噪声的图片然后在我们感兴趣的类别上通过梯度上升逐渐优化输入图片可以产生对应类别的图片。

更一般的, 让$I$ 表示随机产生的噪声图片， $y$ 表示我们感兴趣的类别， $s\_y(I)$ 表示CNN 对图片 $I$ 在类别 $y$上的打分。 我们希望能够产生的图片 $I^\*$ 使得在类别 $y$ 上打分最高。

$$
I^* = \arg\max\_I s\_y(I) - R(I)
$$

其中 $R$ 为正则项， 我们可以通过梯度上升法来求解 。

产生的图片如下所示，可以看出产生的图像对目标的分类又一定的旋转不变形和尺度不变性。
![](http://7xritj.com1.z0.glb.clouddn.com/16-9-22/60627433.jpg)
![](http://7xritj.com1.z0.glb.clouddn.com/16-9-22/72860217.jpg)

### Feature Inversion
为了CNN怎么去学习和理解特征，最近也有文章提出通过提取到的特征重建原图像的方法。我们在训练好的CNN模型的基础上，可以通过对图像的求导来实现。具体来说，给定图片
$I$, 让$\phi\_\ell(I)$ 表示卷积神经$\phi$中 $\ell$ 层所提取到的特征。我们想要求得一张图片$I^\*$ 在网络$\phi$中的$\ell$ 层和图片 $I$有相同的特征。

$$
I^* = \arg\min\_{I'} \|\phi\_\ell(I) - \phi_\ell(I')\|\_2^2 + R(I')
$$

其中 $\|\cdot\|\_2^2$ 为欧式距离，$R$ 表示正则项。

下图展示了从不同层提取的特征重建原图的结果，可以看出层数越深，重建出的结果和原图差异越大，因为CNN在特取特征的过程中，还有一个压缩学习图片最本质特征的作用，所以越往后层，重建得到图片越是代表原图片的本质。
![](http://7xritj.com1.z0.glb.clouddn.com/16-9-23/93123483.jpg)

### DeepDream


2015年夏天，google发布了一种从神经网络产生图片的新方法，原理其实很简单，就是从神经网络中的某一层提取特征，然后让这一层的反向梯度等于这一层提取到的特征，然后在反向传导回图像，通常会选择在卷积层进行操作，所以可以产生任意分辨率的图像。

过程如下，我们先对CNN输入一张原图
![](http://7xritj.com1.z0.glb.clouddn.com/16-9-23/40419664.jpg)
然后选择激活某一层的特征，如果选择的是高层特征，反向传递得到的结果如下，高层特征反向传递得到了一些复杂的模式；

![](http://7xritj.com1.z0.glb.clouddn.com/16-9-23/18649599.jpg)
如果是低层的特征，则得到的是一些线条，纹理特征。
![](http://7xritj.com1.z0.glb.clouddn.com/16-9-23/14566819.jpg)
如果我们把上述输出的结果当成输入再次传入，经过一定次数的循环，一些模式会得到增强，输出结果看起来有点惊悚:
![](http://7xritj.com1.z0.glb.clouddn.com/16-9-23/11926968.jpg)

### 反卷积可视化

反卷积顾名思义是和卷积相反的操作，使用反卷积进行特征的可视化，可以理解为把得到的特征映射回原图像的输入空间。反卷积网络如下图所示，其中下图左边为反卷积网络、右边为卷积网络。其中反卷积网络中的反卷积层和卷积网络中卷积层对应，Unpooling层和pooling层对应。卷积网络是输入图像提取特征，而反卷积网络是从特征映射到输入图像。


![](http://7xritj.com1.z0.glb.clouddn.com/16-9-19/64712899.jpg)

流程如上图所示。

#### 正常卷积过程convnet：

如图右侧黑框流程图部分，上一层pooled的特征图，通过本层的filter卷积后，形成本层的卷积特征，然后经过ReLU函数进行非线性变换的到Recitifed特征图，再经过本层的max-pooling操作，完成本层的卷积池化操作；之后传入下一层。本层需要记录在执行max-pooling操作时，每个pooing局域内最大值的位置

选择激活值：

为了理解某一个给定的pooling特征激活值，先把特征中其他的激活值设置为0；然后利用deconvnet把这个给定的激活值映射到初始像素层。

#### 反卷积过程deconvnet：

Unpooling

顾名思义就是反pooling过程，由于pooling是不可逆的，所以unpooling只是正常pooling的一种近似；通过记录正常pooling时的位置，把传进来的特征按照记录的方式重新“摆放”，来近似pooling前的卷基层特征。如图中彩色部分

Filtering

利用卷积过程filter的转置（实际上就是水平和数值翻转filter）版本来计算卷积前的特征图；从而形成重构的特征。从一个单独的激活值获得的重构图片类似原始图片的一个部分。

反卷积反池化过程如下所示：
![](http://7xritj.com1.z0.glb.clouddn.com/%E9%80%89%E5%8C%BA_006.jpg)

## 总结

通过CNN可视化，我们可以看到底层卷积网络学习到的是一些边缘、颜色块等信息；高层网络通过对底层网络抽取到的特征经行组合，学习到了更加复杂以及具有不变性的特征。特征的可视化都是通过对图片方向求导来计算，通过设置不同的优化函数，梯度下降求导来达到可视化的目的。

## 参考

[Understanding deep image representations by inverting them.](https://arxiv.org/abs/1412.0035)

[Deep neural networks are easily fooled: High confidence predictions for unrecognizable images.](https://arxiv.org/abs/1412.1897)


[Deep inside convolutional networks: Visualising image classification models and saliency maps.](https://arxiv.org/abs/1312.6034)

[Understanding neural networks through deep visualization.](http://arxiv.org/abs/1506.06579)

[Visualizing and understanding convolutional networks.](https://arxiv.org/abs/1311.2901)
